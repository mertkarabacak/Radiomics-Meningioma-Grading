{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxtJ9G-aIZ_y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_PnaQ4NIuE0"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "!pip install tabpfn\n",
        "!pip install catboost\n",
        "!pip install confidenceinterval\n",
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrZMQLTfIQPb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, precision_score, recall_score, f1_score, accuracy_score, matthews_corrcoef, roc_auc_score, average_precision_score, brier_score_loss, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from tabpfn import TabPFNClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from confidenceinterval.bootstrap import bootstrap_ci\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gokg6nyk-G4r"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/adachis/Lifehacker.me/raw/master/fonts/HelveticaNeue.ttf\n",
        "!wget https://github.com/adachis/Lifehacker.me/raw/master/fonts/HelveticaNeue-Bold.ttf\n",
        "\n",
        "matplotlib.font_manager.fontManager.addfont('HelveticaNeue.ttf')\n",
        "matplotlib.font_manager.fontManager.addfont('HelveticaNeue-Bold.ttf')\n",
        "\n",
        "matplotlib.rc('font', family='Helvetica Neue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWbpPFMVHS-V"
      },
      "source": [
        "# Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0-2WL4kM6VF"
      },
      "outputs": [],
      "source": [
        "#Open csv file.\n",
        "\n",
        "clinical_data = pd.read_csv(\"/content/drive/MyDrive/BraTS-MEN/Clinical_Data.csv\", index_col='BraTS ID')\n",
        "radiomic_features = pd.read_csv(\"/content/drive/MyDrive/BraTS-MEN/radiomic_features_train.csv\", index_col=0)\n",
        "\n",
        "data = radiomic_features.join([clinical_data], how='inner')\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb8cjDmSIZrX"
      },
      "outputs": [],
      "source": [
        "# Filter for BraTS IDs ending with -000.\n",
        "\n",
        "data = data[data.index.str.endswith('-000')]\n",
        "\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9TtFoopM6VJ"
      },
      "outputs": [],
      "source": [
        "#Define outcome of interest.\n",
        "\n",
        "data.loc[data['Grade'] == 1, 'OUTCOME'] = 0\n",
        "data.loc[data['Grade'] == 2, 'OUTCOME'] = 1\n",
        "data.loc[data['Grade'] == 3, 'OUTCOME'] = 1\n",
        "data = data.dropna(subset=['OUTCOME'])\n",
        "\n",
        "data = data.drop(list(clinical_data.columns), axis = 1)\n",
        "\n",
        "print(data['OUTCOME'].value_counts(normalize=False, dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJavA0-EM6VK"
      },
      "outputs": [],
      "source": [
        "#Define predictor variables (x) and outcome of interest (y).\n",
        "\n",
        "outcomes = ['OUTCOME']\n",
        "\n",
        "x = data.drop(outcomes, axis = 1)\n",
        "y = data['OUTCOME']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt6ks1daIQPd"
      },
      "outputs": [],
      "source": [
        "#Check data shapes.\n",
        "\n",
        "print(y.shape)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0IwUyCsIQPe"
      },
      "outputs": [],
      "source": [
        "#Split data into initial train set and test set in 80:20 ratio.\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "#Describe initial train set and test set.\n",
        "\n",
        "print(\"Number patients x_train dataset:\", x_train.shape[0])\n",
        "print(\"Number patients y_train dataset:\", y_train.shape[0], \"\\n\")\n",
        "print(\"Number patients x_test dataset:\", x_test.shape[0])\n",
        "print(\"Number patients y_test dataset:\", y_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyNo7C2Pbzt2"
      },
      "outputs": [],
      "source": [
        "#Split initial train set into final train set and validation set in 75:25 ratio.\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.25, random_state = 0)\n",
        "\n",
        "#Describe train and validation sets.\n",
        "\n",
        "print(\"Number patients train_x dataset:\", x_train.shape[0])\n",
        "print(\"Number patients train_y dataset:\", y_train.shape[0], \"\\n\")\n",
        "print(\"Number patients valid_x dataset:\", x_val.shape[0])\n",
        "print(\"Number patients valid_y dataset:\", y_val.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvXczViaIQPe"
      },
      "outputs": [],
      "source": [
        "#Apply SMOTE.\n",
        "\n",
        "print(\"Before resampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before resampling, counts of label '0': {}\".format(sum(y_train == 0)), \"\\n\")\n",
        "\n",
        "resampler = SMOTE(random_state=31)\n",
        "x_train, y_train = resampler.fit_resample(x_train, y_train)\n",
        "\n",
        "print(\"After resampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"After resampling, counts of label '0': {}\".format(sum(y_train == 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez0NapBB1Yjd"
      },
      "outputs": [],
      "source": [
        "# Scale features.\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "def scale_features(data, scaler):\n",
        "    scaled_data = scaler.transform(data)\n",
        "    return pd.DataFrame(scaled_data, columns=data.columns, index=data.index)\n",
        "\n",
        "# Fit and transform the training data.\n",
        "x_train = scale_features(x_train, scaler.fit(x_train))\n",
        "\n",
        "# Transform the validation and test data.\n",
        "x_val = scale_features(x_val, scaler)\n",
        "x_test = scale_features(x_test, scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Acl7bm3vWM"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdEXq-Qx7ttz"
      },
      "outputs": [],
      "source": [
        "# Get a feature importance dataframe with LASSO.\n",
        "\n",
        "def select_features_using_lasso(x, y, alpha=0.001):\n",
        "    lasso = Lasso(alpha=alpha)\n",
        "    lasso.fit(x, y)\n",
        "\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': x.columns,\n",
        "        'Importance': lasso.coef_\n",
        "    })\n",
        "\n",
        "    feature_importance = feature_importance[feature_importance['Importance'] != 0]\n",
        "    feature_importance['Absolute Importance'] = feature_importance['Importance'].abs()\n",
        "    feature_importance = feature_importance.set_index('Feature')\n",
        "    feature_importance = feature_importance.sort_values(by='Absolute Importance', ascending=False)\n",
        "\n",
        "    return feature_importance\n",
        "\n",
        "feature_importance_df = select_features_using_lasso(x_train, y_train)\n",
        "print(\"Number of selected features: \", len(feature_importance_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gej_a-GaTxv"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWX_CriXYlL_"
      },
      "source": [
        "## TabPFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyq8z6VXo2Hw"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter optimization for TabPFN model.\n",
        "\n",
        "def objective_tabpfn(trial):\n",
        "\n",
        "    try:\n",
        "\n",
        "        N_ensemble_configurations = trial.suggest_int(\"N_ensemble_configurations\", 2, 64, log=True)\n",
        "        n_features = trial.suggest_int('n_features', 20, 100, step=1)\n",
        "\n",
        "        selected_features = feature_importance_df.head(n_features).index.tolist()\n",
        "\n",
        "        x_train_selected = x_train[selected_features]\n",
        "        x_val_selected = x_val[selected_features]\n",
        "        x_test_selected = x_test[selected_features]\n",
        "\n",
        "        clf = TabPFNClassifier(device='cpu', N_ensemble_configurations=N_ensemble_configurations).fit(x_train_selected, y_train)\n",
        "\n",
        "        val_preds = clf.predict(x_val_selected)\n",
        "\n",
        "        val_auc = roc_auc_score(y_val, val_preds)\n",
        "\n",
        "        return val_auc\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(\"Trial failed with exception\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# Create an Optuna study.\n",
        "study_tabpfn = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Optimize the hyperparameters.\n",
        "study_tabpfn.optimize(objective_tabpfn, n_trials=100, catch=(Exception,))\n",
        "\n",
        "# Print the best hyperparameters and concordance index.\n",
        "print(\"Best AUROC:\", study_tabpfn.best_value, '\\n')\n",
        "print(\"Best hyperparameters:\", study_tabpfn.best_params)\n",
        "\n",
        "# Store best hyperparameters in tabpfn_param_dict.\n",
        "tabpfn_param_dict = study_tabpfn.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3o6XKtZrRSH"
      },
      "outputs": [],
      "source": [
        "# Apply feature selection for TabPFN model.\n",
        "\n",
        "selected_features = feature_importance_df.head(tabpfn_param_dict.pop('n_features')).index.tolist()\n",
        "\n",
        "x_train_tabpfn = x_train[selected_features]\n",
        "x_val_tabpfn = x_val[selected_features]\n",
        "x_test_tabpfn = x_test[selected_features]\n",
        "\n",
        "print('x_train shape:', x_train_tabpfn.shape)\n",
        "print('x_val shape:', x_val_tabpfn.shape)\n",
        "print('x_test shape:', x_test_tabpfn.shape, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3gvvODJ8B2Z"
      },
      "outputs": [],
      "source": [
        "# Fit TabPFN model.\n",
        "\n",
        "tabpfn_model = TabPFNClassifier(device='cpu', **tabpfn_param_dict)\n",
        "\n",
        "tabpfn_model.fit(x_train_tabpfn, y_train, overwrite_warning = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oLbONin8YGA"
      },
      "outputs": [],
      "source": [
        "# Calibrate TabPFN model using CalibratedClassifierCV.\n",
        "\n",
        "calibrated_tabpfn_model = CalibratedClassifierCV(tabpfn_model, method='sigmoid', cv='prefit')\n",
        "calibrated_tabpfn_model.fit(x_val_tabpfn, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZNInXD39Tux"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set based on the trained TabPFN model.\n",
        "\n",
        "probs_tabpfn = calibrated_tabpfn_model.predict_proba(x_test_tabpfn)\n",
        "probs_tabpfn = probs_tabpfn[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esuV5nR8IQPe"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPoWcd73k8xE"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter optimization for XGBoost model.\n",
        "\n",
        "def objective_xgboost(trial):\n",
        "\n",
        "    try:\n",
        "\n",
        "        params = {\n",
        "            \"verbosity\": 0,\n",
        "            \"objective\":  trial.suggest_categorical(\"objective\", [\"binary:logistic\"]),\n",
        "            \"eval_metric\": \"auc\",\n",
        "            \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),\n",
        "            \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "            \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "            \"max_depth\" : trial.suggest_int(\"max_depth\", 1, 9),\n",
        "            \"eta\" : trial.suggest_float(\"eta\", 1e-8, 1.0, log=True),\n",
        "            \"gamma\" : trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),\n",
        "            \"grow_policy\" : trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "        }\n",
        "\n",
        "        n_features = trial.suggest_int('n_features', 1,  len(feature_importance_df), step=1)\n",
        "\n",
        "        selected_features = feature_importance_df.head(n_features).index.tolist()\n",
        "\n",
        "        x_train_selected = x_train[selected_features]\n",
        "        x_val_selected = x_val[selected_features]\n",
        "        x_test_selected = x_test[selected_features]\n",
        "\n",
        "        clf = XGBClassifier(seed=31, **params).fit(x_train_selected, y_train)\n",
        "        val_preds = clf.predict(x_val_selected)\n",
        "\n",
        "        val_auc = roc_auc_score(y_val, val_preds)\n",
        "\n",
        "        return val_auc\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(\"Trial failed with exception\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# Create an Optuna study.\n",
        "study_xgb = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Optimize the hyperparameters.\n",
        "study_xgb.optimize(objective_xgboost, n_trials=100, catch=(Exception,))\n",
        "\n",
        "# Print the best hyperparameters and concordance index.\n",
        "print(\"Best AUROC:\", study_xgb.best_value, '\\n')\n",
        "print(\"Best hyperparameters:\", study_xgb.best_params)\n",
        "\n",
        "# Store best hyperparameters in xgboost_param_dict.\n",
        "xgb_param_dict = study_xgb.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6sXNm3xnZCu"
      },
      "outputs": [],
      "source": [
        "# Apply feature selection for XGBoost model.\n",
        "\n",
        "selected_features = feature_importance_df.head(xgb_param_dict.pop('n_features')).index.tolist()\n",
        "\n",
        "x_train_xgb = x_train[selected_features]\n",
        "x_val_xgb = x_val[selected_features]\n",
        "x_test_xgb = x_test[selected_features]\n",
        "\n",
        "print('x_train shape:', x_train_xgb.shape)\n",
        "print('x_val shape:', x_val_xgb.shape)\n",
        "print('x_test shape:', x_test_xgb.shape, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZk8hbTUIQPg"
      },
      "outputs": [],
      "source": [
        "# Fit XGBoost.\n",
        "\n",
        "xgb_model = XGBClassifier(seed=31, **xgb_param_dict)\n",
        "\n",
        "xgb_model.fit(x_train_xgb, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUf-OtCoIQPg"
      },
      "outputs": [],
      "source": [
        "# Calibrate TabPFN using CalibratedClassifierCV.\n",
        "\n",
        "calibrated_xgb_model = CalibratedClassifierCV(xgb_model, method='sigmoid', cv='prefit')\n",
        "calibrated_xgb_model.fit(x_val_xgb, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq-OU3c29-4L"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set based on the trained TabPFN model.\n",
        "\n",
        "probs_xgb = calibrated_xgb_model.predict_proba(x_test_xgb)\n",
        "probs_xgb = probs_xgb[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VszU3k5IQPh"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR81p9HpIQPh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter optimization for LightGBM model.\n",
        "\n",
        "def objective_lgb(trial):\n",
        "\n",
        "    try:\n",
        "\n",
        "        params = {\n",
        "            \"objective\":  trial.suggest_categorical(\"objective\", [\"binary\"]),\n",
        "            \"metric\": \"binary_logloss\",\n",
        "            \"verbosity\": -1,\n",
        "            \"random_state\": 31,\n",
        "            \"boosting_type\":  trial.suggest_categorical(\"boosting_type\", [\"gbdt\"]),\n",
        "            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
        "            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
        "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
        "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
        "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
        "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
        "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
        "        }\n",
        "\n",
        "        n_features = trial.suggest_int('n_features', 1, len(feature_importance_df), step=1)\n",
        "\n",
        "        selected_features = feature_importance_df.head(n_features).index.tolist()\n",
        "\n",
        "        x_train_selected = x_train[selected_features]\n",
        "        x_val_selected = x_val[selected_features]\n",
        "        x_test_selected = x_test[selected_features]\n",
        "\n",
        "        clf = LGBMClassifier(seed=31, **params).fit(x_train_selected, y_train)\n",
        "\n",
        "        val_preds = clf.predict(x_val_selected)\n",
        "\n",
        "        val_auc = roc_auc_score(y_val, val_preds)\n",
        "\n",
        "        return val_auc\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(\"Trial failed with exception\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# Create an Optuna study.\n",
        "study_lgb = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Optimize the hyperparameters.\n",
        "study_lgb.optimize(objective_lgb, n_trials=100, catch=(Exception,))\n",
        "\n",
        "# Print the best hyperparameters and concordance index.\n",
        "print(\"Best AUROC:\", study_lgb.best_value, '\\n')\n",
        "print(\"Best hyperparameters:\", study_lgb.best_params)\n",
        "\n",
        "# Store best hyperparameters in lgb_param_dict.\n",
        "lgb_param_dict = study_lgb.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7P7Mw7UkC-y"
      },
      "outputs": [],
      "source": [
        "# Apply feature selection for LightGBM model.\n",
        "\n",
        "selected_features = feature_importance_df.head(lgb_param_dict.pop('n_features')).index.tolist()\n",
        "\n",
        "x_train_lgb = x_train[selected_features]\n",
        "x_val_lgb = x_val[selected_features]\n",
        "x_test_lgb = x_test[selected_features]\n",
        "\n",
        "print('x_train shape:', x_train_lgb.shape)\n",
        "print('x_val shape:', x_val_lgb.shape)\n",
        "print('x_test shape:', x_test_lgb.shape, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAidUSs1IQPh"
      },
      "outputs": [],
      "source": [
        "# Fit LightGBM model.\n",
        "\n",
        "lgb_model = LGBMClassifier(random_state=31, **lgb_param_dict)\n",
        "\n",
        "lgb_model.fit(x_train_lgb, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlKe1z0RIQPh"
      },
      "outputs": [],
      "source": [
        "# Calibrate LightGBM model using CalibratedClassifierCV.\n",
        "\n",
        "calibrated_lgb_model = CalibratedClassifierCV(lgb_model, method='sigmoid', cv='prefit')\n",
        "calibrated_lgb_model.fit(x_val_lgb, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPyYlwGX-HkZ"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set based on the trained LightGBM model.\n",
        "\n",
        "probs_lgb = calibrated_lgb_model.predict_proba(x_test_lgb)\n",
        "probs_lgb = probs_lgb[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0iGfJFxzulz"
      },
      "source": [
        "## CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xkAGhVM03GJ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter optimization for CatBoost model.\n",
        "\n",
        "def objective_cb(trial):\n",
        "\n",
        "    try:\n",
        "\n",
        "        params = {\n",
        "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
        "            \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
        "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-8, 10.0, log=True),\n",
        "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
        "            \"random_strength\": trial.suggest_float(\"random_strength\", 0.0, 10.0),\n",
        "            \"border_count\": trial.suggest_int(\"border_count\", 1, 255),\n",
        "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.0, 10.0),\n",
        "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "            \"leaf_estimation_iterations\": trial.suggest_int(\"leaf_estimation_iterations\", 1, 10),\n",
        "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.4, 1.0),\n",
        "            \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
        "            \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
        "        }\n",
        "\n",
        "        n_features = trial.suggest_int('n_features', 1, len(feature_importance_df), step=1)\n",
        "\n",
        "        selected_features = feature_importance_df.head(n_features).index.tolist()\n",
        "\n",
        "        x_train_selected = x_train[selected_features]\n",
        "        x_val_selected = x_val[selected_features]\n",
        "        x_test_selected = x_test[selected_features]\n",
        "\n",
        "        clf = CatBoostClassifier(**params).fit(x_train_selected, y_train)\n",
        "\n",
        "        val_preds = clf.predict(x_val_selected)\n",
        "\n",
        "        val_auc = roc_auc_score(y_val, val_preds)\n",
        "\n",
        "        return val_auc\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(\"Trial failed with exception\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# Create an Optuna study.\n",
        "study_cb = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Optimize the hyperparameters.\n",
        "study_cb.optimize(objective_cb, n_trials=100, catch=(Exception,))\n",
        "\n",
        "# Print the best hyperparameters and concordance index.\n",
        "print(\"Best AUROC:\", study_cb.best_value, '\\n')\n",
        "print(\"Best hyperparameters:\", study_cb.best_params)\n",
        "\n",
        "# Store best hyperparameters in cb_param_dict.\n",
        "cb_param_dict = study_cb.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvADuOQo1MNA"
      },
      "outputs": [],
      "source": [
        "# Apply feature selection for CatBoost model.\n",
        "\n",
        "selected_features = feature_importance_df.head(cb_param_dict.pop('n_features')).index.tolist()\n",
        "\n",
        "x_train_cb = x_train[selected_features]\n",
        "x_val_cb = x_val[selected_features]\n",
        "x_test_cb = x_test[selected_features]\n",
        "\n",
        "print('x_train shape:', x_train_cb.shape)\n",
        "print('x_val shape:', x_val_cb.shape)\n",
        "print('x_test shape:', x_test_cb.shape, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaH5Uc5m1X_C"
      },
      "outputs": [],
      "source": [
        "# Fit CatBoost model.\n",
        "\n",
        "cb_model = CatBoostClassifier(random_seed=31, **cb_param_dict)\n",
        "\n",
        "cb_model.fit(x_train_cb, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NPXlcvgIFqT"
      },
      "outputs": [],
      "source": [
        "# Calibrate CatBoost model using CalibratedClassifierCV.\n",
        "\n",
        "calibrated_cb_model = CalibratedClassifierCV(cb_model, method='sigmoid', cv='prefit')\n",
        "calibrated_cb_model.fit(x_val_cb, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fkVHnUN1n3O"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set based on the trained CatBoost model.\n",
        "\n",
        "probs_cb = calibrated_cb_model.predict_proba(x_test_cb)\n",
        "probs_cb = probs_cb[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQRRrBp-IQPk"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFTmQMQxIQPk"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter optimization for Random Forest model.\n",
        "\n",
        "def objective_rf(trial):\n",
        "\n",
        "    try:\n",
        "\n",
        "        params = {\n",
        "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
        "            \"random_state\": 31,\n",
        "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\",\"log2\", None]),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 100),\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 2000, 100),\n",
        "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4, 1),\n",
        "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10, 1),\n",
        "        }\n",
        "\n",
        "        n_features = trial.suggest_int('n_features', 20, len(feature_importance_df), step=1)\n",
        "\n",
        "        selected_features = feature_importance_df.head(n_features).index.tolist()\n",
        "\n",
        "        x_train_selected = x_train[selected_features]\n",
        "        x_val_selected = x_val[selected_features]\n",
        "        x_test_selected = x_test[selected_features]\n",
        "\n",
        "        clf = RandomForestClassifier(**params).fit(x_train_selected, y_train)\n",
        "\n",
        "        val_preds = clf.predict(x_val_selected)\n",
        "\n",
        "        val_auc = roc_auc_score(y_val, val_preds)\n",
        "\n",
        "        return val_auc\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(\"Trial failed with exception\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# Create an Optuna study.\n",
        "study_rf = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Optimize the hyperparameters.\n",
        "study_rf.optimize(objective_rf, n_trials=100, catch=(Exception,))\n",
        "\n",
        "# Print the best hyperparameters and concordance index.\n",
        "print(\"Best AUROC:\", study_rf.best_value, '\\n')\n",
        "print(\"Best hyperparameters:\", study_rf.best_params)\n",
        "\n",
        "# Store best hyperparameters in rf_param_dict.\n",
        "rf_param_dict = study_rf.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTqnQTzgkG3R"
      },
      "outputs": [],
      "source": [
        "# Apply feature selection for Random Forest model.\n",
        "\n",
        "selected_features = feature_importance_df.head(rf_param_dict.pop('n_features')).index.tolist()\n",
        "\n",
        "x_train_rf = x_train[selected_features]\n",
        "x_val_rf = x_val[selected_features]\n",
        "x_test_rf = x_test[selected_features]\n",
        "\n",
        "print('x_train shape:', x_train_rf.shape)\n",
        "print('x_val shape:', x_val_rf.shape)\n",
        "print('x_test shape:', x_test_rf.shape, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2nnbDAsIQPk"
      },
      "outputs": [],
      "source": [
        "# Fit Random Forest model.\n",
        "\n",
        "rf_model = RandomForestClassifier(**rf_param_dict)\n",
        "\n",
        "rf_model.fit(x_train_rf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSsBliFuIQPk"
      },
      "outputs": [],
      "source": [
        "# Calibrate Random Forest model using CalibratedClassifierCV.\n",
        "\n",
        "calibrated_rf_model = CalibratedClassifierCV(rf_model, method='sigmoid', cv='prefit')\n",
        "calibrated_rf_model.fit(x_val_rf, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Ru1zLF-YER"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set based on the trained Random Forest model.\n",
        "\n",
        "probs_rf = calibrated_rf_model.predict_proba(x_test_rf)\n",
        "probs_rf = probs_rf[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faHclS5kPdKw"
      },
      "source": [
        "# Performance Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1MZM60az07x"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4EYga4XPhJx"
      },
      "outputs": [],
      "source": [
        "# Define performance evaluation function.\n",
        "\n",
        "def evaluate_performance(y_true, y_pred_prob, confidence_level=0.95):\n",
        "\n",
        "    #Find the optimum classification threshold.\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "\n",
        "    optimal_idx = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "    y_pred = np.where(y_pred_prob >= optimal_threshold, 1, 0)\n",
        "\n",
        "    # Calculate performance metrics.\n",
        "\n",
        "    precision, precision_ci = bootstrap_ci(y_true=y_true, y_pred=y_pred, metric=precision_score, confidence_level=confidence_level, n_resamples=1000, method='bootstrap_bca', random_state=31)\n",
        "    recall, recall_ci = bootstrap_ci(y_true=y_true, y_pred=y_pred, metric=recall_score, confidence_level=confidence_level, n_resamples=1000, method='bootstrap_bca', random_state=31)\n",
        "    f1, fi_ci = bootstrap_ci(y_true=y_true, y_pred=y_pred, metric=f1_score, confidence_level=confidence_level, n_resamples=1000, method='bootstrap_bca', random_state=31)\n",
        "    accuracy, accuracy_ci = bootstrap_ci(y_true=y_true, y_pred=y_pred, metric=accuracy_score, confidence_level=confidence_level, n_resamples=1000, method='bootstrap_bca', random_state=31)\n",
        "    mcc, mcc_ci = bootstrap_ci(y_true=y_true, y_pred=y_pred, metric=matthews_corrcoef, confidence_level=confidence_level, n_resamples=1000, method='bootstrap_bca', random_state=31)\n",
        "    auroc, auroc_ci = bootstrap_ci(y_true=y_true, y_pred=y_pred_prob, metric=roc_auc_score, confidence_level=confidence_level, n_resamples=1000, method='bootstrap_bca', random_state=31)\n",
        "    auprc, auprc_ci = bootstrap_ci(y_true=y_true, y_pred=y_pred_prob, metric=average_precision_score, confidence_level=confidence_level, n_resamples=1000, method='bootstrap_bca', random_state=31)\n",
        "    brier, brier_ci = bootstrap_ci(y_true=y_true, y_pred=y_pred_prob, metric=brier_score_loss, confidence_level=confidence_level, n_resamples=1000, method='bootstrap_bca', random_state=31)\n",
        "\n",
        "    precision_ci_lower, precision_ci_upper = precision_ci\n",
        "    recall_ci_lower, recall_ci_upper = recall_ci\n",
        "    f1_ci_lower, f1_ci_upper = fi_ci\n",
        "    accuracy_ci_lower, accuracy_ci_upper = accuracy_ci\n",
        "    mcc_ci_lower, mcc_ci_upper = mcc_ci\n",
        "    auroc_ci_lower, auroc_ci_upper = auroc_ci\n",
        "    auprc_ci_lower, auprc_ci_upper = auprc_ci\n",
        "    brier_ci_lower, brier_ci_upper = brier_ci\n",
        "\n",
        "    precision_str = f\"{precision:.3f} ({precision_ci_lower:.3f}-{precision_ci_upper:.3f})\"\n",
        "    recall_str = f\"{recall:.3f} ({recall_ci_lower:.3f}-{recall_ci_upper:.3f})\"\n",
        "    f1_str = f\"{f1:.3f} ({f1_ci_lower:.3f}-{f1_ci_upper:.3f})\"\n",
        "    accuracy_str = f\"{accuracy:.3f} ({accuracy_ci_lower:.3f}-{accuracy_ci_upper:.3f})\"\n",
        "    mcc_str = f\"{mcc:.3f} ({mcc_ci_lower:.3f}-{mcc_ci_upper:.3f})\"\n",
        "    auroc_str = f\"{auroc:.3f} ({auroc_ci_lower:.3f}-{auroc_ci_upper:.3f})\"\n",
        "    auprc_str = f\"{auprc:.3f} ({auprc_ci_lower:.3f}-{auprc_ci_upper:.3f})\"\n",
        "    brier_str = f\"{brier:.3f} ({brier_ci_lower:.3f}-{brier_ci_upper:.3f})\"\n",
        "    optimal_threshold_str = f\"{optimal_threshold*100:.1f}%\"\n",
        "\n",
        "    # Print the performance metrics.\n",
        "\n",
        "    print(\"Precision:\", precision_str)\n",
        "    print(\"Recall:\", recall_str)\n",
        "    print(\"F1 Score:\", f1_str)\n",
        "    print(\"Accuracy:\", accuracy_str)\n",
        "    print(\"MCC:\", mcc_str)\n",
        "    print(\"AUROC:\", auroc_str)\n",
        "    print(\"AUPRC:\", auprc_str)\n",
        "    print(\"Brier Score:\", brier_str)\n",
        "    print(\"Optimal Classification Threshold:\", optimal_threshold_str, '\\n')\n",
        "\n",
        "    metrics = {'Precision': precision_str, 'Recall': recall_str, 'F1 Score': f1_str, 'Accuracy': accuracy_str, 'MCC': mcc_str, 'AUROC': auroc_str, 'AUPRC': auprc_str, 'Brier Score': brier_str, 'Optimal Classification Threshold': optimal_threshold_str}\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhN1cerkPfI5"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performances on test set.\n",
        "\n",
        "metrics_tabpfn = evaluate_performance(y_test, probs_tabpfn, confidence_level=0.95)\n",
        "metrics_xgb = evaluate_performance(y_test, probs_xgb, confidence_level=0.95)\n",
        "metrics_lgb = evaluate_performance(y_test, probs_lgb, confidence_level=0.95)\n",
        "metrics_cb = evaluate_performance(y_test, probs_cb, confidence_level=0.95)\n",
        "metrics_rf = evaluate_performance(y_test, probs_rf, confidence_level=0.95)\n",
        "\n",
        "results = pd.DataFrame([metrics_tabpfn, metrics_xgb, metrics_lgb, metrics_cb, metrics_rf])\n",
        "results.index = ['TabPFN', 'XGBoost', 'LightGBM', 'CatBoost', 'Random Forest']\n",
        "results = results.T\n",
        "results.to_csv('/content/drive/MyDrive/Meningioma-Radiomics-Grading/metrics_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLvNgketIQPl"
      },
      "source": [
        "## ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mMqO-euIQPl"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curves for test set.\n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(10)\n",
        "f.set_figheight(10)\n",
        "\n",
        "tabpfn_label = 'TabPFN Model Mean AUROC: ' + metrics_tabpfn['AUROC'].split(' ')[0]\n",
        "xgb_label = 'XGBoost Model Mean AUROC: ' + metrics_xgb['AUROC'].split(' ')[0]\n",
        "lgb_label = 'LightGBM Model Mean AUROC: ' + metrics_lgb['AUROC'].split(' ')[0]\n",
        "cb_label = 'CatBoost Model Mean AUROC: ' + metrics_cb['AUROC'].split(' ')[0]\n",
        "rf_label = 'Random Forest Model Mean AUROC: ' + metrics_rf['AUROC'].split(' ')[0]\n",
        "\n",
        "test_fpr_tabpfn, test_tpr_tabpfn, _ = roc_curve(y_test, probs_tabpfn)\n",
        "test_fpr_xgb, test_tpr_xgb, _ = roc_curve(y_test, probs_xgb)\n",
        "test_fpr_lgb, test_tpr_lgb, _ = roc_curve(y_test, probs_lgb)\n",
        "test_fpr_cb, test_tpr_cb, _ = roc_curve(y_test, probs_cb)\n",
        "test_fpr_rf, test_tpr_rf, _ = roc_curve(y_test, probs_rf)\n",
        "\n",
        "plt.plot(test_fpr_tabpfn, test_tpr_tabpfn, label=tabpfn_label, color='#911eb4', linewidth=3, alpha=0.8)\n",
        "plt.plot(test_fpr_xgb, test_tpr_xgb, label=xgb_label, color='#4363d8', linewidth=3, alpha=0.8)\n",
        "plt.plot(test_fpr_lgb, test_tpr_lgb, label=lgb_label, color='#3cb44b', linewidth=3, alpha=0.8)\n",
        "plt.plot(test_fpr_cb, test_tpr_cb, label=cb_label, color='#ffe119', linewidth=3, alpha=0.8)\n",
        "plt.plot(test_fpr_rf, test_tpr_rf, label=rf_label, color='#e6194B', linewidth=3, alpha=0.8)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='black', linestyle='--', linewidth=2, alpha=0.25, label='Random Classifier Benchmark')\n",
        "\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.25, color='gray', alpha=0.5)\n",
        "plt.grid(True, which='minor', linestyle=':', linewidth=0.25, color='gray', alpha=0.5)\n",
        "\n",
        "plt.gca().xaxis.set_minor_locator(MultipleLocator(0.1))\n",
        "plt.gca().yaxis.set_minor_locator(MultipleLocator(0.1))\n",
        "\n",
        "plt.ylim(-0.01, 1.01)\n",
        "plt.xlim(-0.01, 1.01)\n",
        "\n",
        "plt.tick_params(axis=\"y\", direction=\"out\", labelsize=18)\n",
        "plt.tick_params(axis=\"x\", direction=\"out\", labelsize=18)\n",
        "\n",
        "plt.text(-0.25, 0.95, 'A', fontsize=75)\n",
        "\n",
        "plt.xlabel('False Positive Rate', fontsize=26, labelpad=12, fontweight='bold')\n",
        "plt.ylabel('True Positive Rate', fontsize=26, labelpad=12, fontweight='bold')\n",
        "\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, fontsize=18)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/roc_test.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv2QSED0z5zU"
      },
      "source": [
        "## PR Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpotrYFBIQPl"
      },
      "outputs": [],
      "source": [
        "# Plot PR curves for test set.\n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(10)\n",
        "f.set_figheight(10)\n",
        "\n",
        "tabpfn_label = 'TabPFN Model Mean AUPRC: ' + metrics_tabpfn['AUPRC'].split(' ')[0]\n",
        "xgb_label = 'XGBoost Model Mean AUPRC: ' + metrics_xgb['AUPRC'].split(' ')[0]\n",
        "lgb_label = 'LightGBM Model Mean AUPRC: ' + metrics_lgb['AUPRC'].split(' ')[0]\n",
        "cb_label = 'CatBoost Model Mean AUPRC: ' + metrics_cb['AUPRC'].split(' ')[0]\n",
        "rf_label = 'Random Forest Model Mean AUPRC: ' + metrics_rf['AUPRC'].split(' ')[0]\n",
        "\n",
        "test_precision_tabpfn, test_recall_tabpfn, _ = precision_recall_curve(y_test, probs_tabpfn)\n",
        "test_precision_xgb, test_recall_xgb, _ = precision_recall_curve(y_test, probs_xgb)\n",
        "test_precision_lgb, test_recall_lgb, _ = precision_recall_curve(y_test, probs_lgb)\n",
        "test_precision_cb, test_recall_cb, _ = precision_recall_curve(y_test, probs_cb)\n",
        "test_precision_rf, test_recall_rf, _ = precision_recall_curve(y_test, probs_rf)\n",
        "\n",
        "plt.plot(test_recall_tabpfn, test_precision_tabpfn, label=tabpfn_label, color='#911eb4', linewidth=3, alpha=0.8)\n",
        "plt.plot(test_recall_xgb, test_precision_xgb, label=xgb_label, color='#4363d8', linewidth=3, alpha=0.8)\n",
        "plt.plot(test_recall_lgb, test_precision_lgb, label=lgb_label, color='#3cb44b', linewidth=3, alpha=0.8)\n",
        "plt.plot(test_recall_cb, test_precision_cb, label=cb_label, color='#ffe119', linewidth=3, alpha=0.8)\n",
        "plt.plot(test_recall_rf, test_precision_rf, label=rf_label, color='#e6194B', linewidth=3, alpha=0.8)\n",
        "\n",
        "plt.axhline(y=y_test.value_counts(normalize=True)[1.0], color='black', linestyle='--', linewidth=2, alpha = 0.25, label='Random Classifier Benchmark')\n",
        "\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.25, color='gray', alpha=0.5)\n",
        "plt.grid(True, which='minor', linestyle=':', linewidth=0.25, color='gray', alpha=0.5)\n",
        "\n",
        "plt.gca().xaxis.set_minor_locator(MultipleLocator(0.1))\n",
        "plt.gca().yaxis.set_minor_locator(MultipleLocator(0.1))\n",
        "\n",
        "plt.ylim(-0.01, 1.01)\n",
        "plt.xlim(-0.01, 1.01)\n",
        "\n",
        "plt.tick_params(axis=\"y\", direction=\"out\", labelsize=18)\n",
        "plt.tick_params(axis=\"x\", direction=\"out\", labelsize=18)\n",
        "\n",
        "plt.text(-0.25, 0.95, 'B', fontsize=75)\n",
        "\n",
        "plt.xlabel('Recall', fontsize=26, labelpad=12, fontweight='bold')\n",
        "plt.ylabel('Precision', fontsize=26, labelpad=12, fontweight='bold')\n",
        "\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, fontsize=18)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/prc_test.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqXlqBCjBsmH"
      },
      "source": [
        "## Calibration Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5r-OuOaBneQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "# Plot calibration curves for test set.\n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(10)\n",
        "f.set_figheight(10)\n",
        "\n",
        "tabpfn_label = 'TabPFN Model Mean Brier Score: ' + metrics_tabpfn['Brier Score'].split(' ')[0]\n",
        "xgb_label = 'XGBoost Model Mean Brier Score: ' + metrics_xgb['Brier Score'].split(' ')[0]\n",
        "lgb_label = 'LightGBM Model Mean Brier Score: ' + metrics_lgb['Brier Score'].split(' ')[0]\n",
        "cb_label = 'CatBoost Model Mean Brier Score: ' + metrics_cb['Brier Score'].split(' ')[0]\n",
        "rf_label = 'Random Forest Model Mean Brier Score: ' + metrics_rf['Brier Score'].split(' ')[0]\n",
        "\n",
        "x_cal_tabpfn, y_cal_tabpfn = calibration_curve(y_test, probs_tabpfn, n_bins = 6)\n",
        "x_cal_xgb, y_cal_xgb = calibration_curve(y_test, probs_xgb, n_bins = 4)\n",
        "x_cal_lgb, y_cal_lgb = calibration_curve(y_test, probs_lgb, n_bins = 6)\n",
        "x_cal_cb, y_cal_cb = calibration_curve(y_test, probs_cb, n_bins = 6)\n",
        "x_cal_rf, y_cal_rf = calibration_curve(y_test, probs_rf, n_bins = 5)\n",
        "\n",
        "plt.plot(y_cal_tabpfn, x_cal_tabpfn, label=tabpfn_label, color='#911eb4', linewidth=3, alpha=0.8)\n",
        "plt.plot(y_cal_xgb, x_cal_xgb, label=xgb_label, color='#4363d8', linewidth=3, alpha=0.8)\n",
        "plt.plot(y_cal_lgb, x_cal_lgb, label=lgb_label, color='#3cb44b', linewidth=3, alpha=0.8)\n",
        "plt.plot(y_cal_cb, x_cal_cb, label=cb_label, color='#ffe119', linewidth=3, alpha=0.8)\n",
        "plt.plot(y_cal_rf, x_cal_rf, label=rf_label, color='#e6194B', linewidth=3, alpha=0.8)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='black', linestyle='--', linewidth=2, alpha=0.25, label='Ideal Calibration')\n",
        "\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.25, color='gray', alpha=0.5)\n",
        "plt.grid(True, which='minor', linestyle=':', linewidth=0.25, color='gray', alpha=0.5)\n",
        "\n",
        "plt.gca().xaxis.set_minor_locator(MultipleLocator(0.1))\n",
        "plt.gca().yaxis.set_minor_locator(MultipleLocator(0.1))\n",
        "\n",
        "plt.ylim(-0.01, 1.01)\n",
        "plt.xlim(-0.01, 1.01)\n",
        "\n",
        "plt.tick_params(axis=\"y\", direction=\"out\", labelsize=18)\n",
        "plt.tick_params(axis=\"x\", direction=\"out\", labelsize=18)\n",
        "\n",
        "plt.text(-0.25, 0.95, 'C', fontsize=75)\n",
        "\n",
        "plt.xlabel('Average Predicted Probability', fontsize=26, labelpad=12, fontweight='bold')\n",
        "plt.ylabel('Ratio of Positives', fontsize=26, labelpad=12, fontweight='bold')\n",
        "\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, fontsize=18)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/cal_test.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAD5jLGchIp4"
      },
      "source": [
        "## Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoCklZB3h1da"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Create the custom colormap.\n",
        "\n",
        "cmap_tabpfn = LinearSegmentedColormap.from_list('custom_cmap', ['#FFFFFF', '#911eb4'])\n",
        "cmap_xgb = LinearSegmentedColormap.from_list('custom_cmap', ['#FFFFFF', '#4363d8'])\n",
        "cmap_lgb = LinearSegmentedColormap.from_list('custom_cmap', ['#FFFFFF', '#3cb44b'])\n",
        "cmap_cb = LinearSegmentedColormap.from_list('custom_cmap', ['#FFFFFF', '#ffe119'])\n",
        "cmap_rf = LinearSegmentedColormap.from_list('custom_cmap', ['#FFFFFF', '#e6194B'])\n",
        "\n",
        "# Define a function for binarizing predictions.\n",
        "\n",
        "def binarize_predictions(y_pred, threshold):\n",
        "    return [1 if x >= threshold else 0 for x in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "envFlVxXd92j"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix for TabPFN model.\n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(5)\n",
        "f.set_figheight(5)\n",
        "\n",
        "y_pred_binarized_tabpfn = binarize_predictions(probs_tabpfn, float(metrics_tabpfn['Optimal Classification Threshold'].split('%')[0]) / 100)\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_binarized_tabpfn), fmt='d', annot=True, cmap=cmap_tabpfn, cbar=False,\n",
        "            annot_kws={\"size\": 16}, linewidths=1, linecolor='black')\n",
        "\n",
        "labels = ['Low-Grade', 'High-Grade']\n",
        "plt.xticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy')\n",
        "plt.yticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy', rotation=90)\n",
        "\n",
        "plt.xlabel('Predicted', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "plt.ylabel('Truth', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "\n",
        "plt.title('A', x=-0.3, y=0.85, fontsize=65, pad=10)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/cm_tabpfn.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxfMkERuFtF5"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix for TabPFN model.\n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(5)\n",
        "f.set_figheight(5)\n",
        "\n",
        "y_pred_binarized_xgb = binarize_predictions(probs_xgb, float(metrics_xgb['Optimal Classification Threshold'].split('%')[0]) / 100)\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_binarized_xgb), fmt='d', annot=True, cmap=cmap_xgb, cbar=False,\n",
        "            annot_kws={\"size\": 16}, linewidths=1, linecolor='black')\n",
        "\n",
        "labels = ['Low-Grade', 'High-Grade']\n",
        "plt.xticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy')\n",
        "plt.yticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy', rotation=90)\n",
        "\n",
        "plt.xlabel('Predicted', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "plt.ylabel('Truth', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "\n",
        "plt.title('B', x=-0.3, y=0.85, fontsize=65, pad=10)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/cm_xgb.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foIz0Bl9FvmX"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix for TabPFN model.\n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(5)\n",
        "f.set_figheight(5)\n",
        "\n",
        "y_pred_binarized_lgb = binarize_predictions(probs_lgb, float(metrics_lgb['Optimal Classification Threshold'].split('%')[0]) / 100)\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_binarized_lgb), fmt='d', annot=True, cmap=cmap_lgb, cbar=False,\n",
        "            annot_kws={\"size\": 16}, linewidths=1, linecolor='black')\n",
        "\n",
        "labels = ['Low-Grade', 'High-Grade']\n",
        "plt.xticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy')\n",
        "plt.yticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy', rotation=90)\n",
        "\n",
        "plt.xlabel('Predicted', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "plt.ylabel('Truth', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "\n",
        "plt.title('C', x=-0.3, y=0.85, fontsize=65, pad=10)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/cm_lgb.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ine9KancF18S"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix for TabPFN model.\n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(5)\n",
        "f.set_figheight(5)\n",
        "\n",
        "y_pred_binarized_cb = binarize_predictions(probs_cb, float(metrics_cb['Optimal Classification Threshold'].split('%')[0]) / 100)\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_binarized_cb), fmt='d', annot=True, cmap=cmap_cb, cbar=False,\n",
        "            annot_kws={\"size\": 16}, linewidths=1, linecolor='black')\n",
        "\n",
        "labels = ['Low-Grade', 'High-Grade']\n",
        "plt.xticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy')\n",
        "plt.yticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy', rotation=90)\n",
        "\n",
        "plt.xlabel('Predicted', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "plt.ylabel('Truth', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "\n",
        "plt.title('D', x=-0.3, y=0.85, fontsize=65, pad=10)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/cm_cb.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmHd9nthF35l"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix for TabPFN model.\n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(5)\n",
        "f.set_figheight(5)\n",
        "\n",
        "y_pred_binarized_rf = binarize_predictions(probs_rf, float(metrics_rf['Optimal Classification Threshold'].split('%')[0]) / 100)\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_binarized_rf), fmt='d', annot=True, cmap=cmap_rf, cbar=False,\n",
        "            annot_kws={\"size\": 16}, linewidths=1, linecolor='black')\n",
        "\n",
        "labels = ['Low-Grade', 'High-Grade']\n",
        "plt.xticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy')\n",
        "plt.yticks([0.5, 1.5], labels, fontsize=16, fontweight='heavy', rotation=90)\n",
        "\n",
        "plt.xlabel('Predicted', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "plt.ylabel('Truth', fontsize=18, fontweight='heavy', labelpad=16)\n",
        "\n",
        "plt.title('E', x=-0.3, y=0.85, fontsize=65, pad=10)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/cm_rf.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYnu4PnCIQPm"
      },
      "source": [
        "# SHAP Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YhR1VsFYLxhq"
      },
      "outputs": [],
      "source": [
        "#Calculate SHAP values for TabPFN.\n",
        "\n",
        "tabpfn_explainer = shap.Explainer(calibrated_tabpfn_model.predict, x_test_tabpfn)\n",
        "tabpfn_shap_values = tabpfn_explainer(x_test_tabpfn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_0cOlZVqThzU"
      },
      "outputs": [],
      "source": [
        "# Plot SHAP bar plot for TabPFN.\n",
        "\n",
        "shap.plots.bar(tabpfn_shap_values, max_display=20, show=False)\n",
        "\n",
        "fig = plt.gcf()\n",
        "ax = plt.gca()\n",
        "fig.set_figheight(15)\n",
        "fig.set_figwidth(5)\n",
        "\n",
        "# Change the color of the bars\n",
        "for bar in ax.patches:\n",
        "    bar.set_color('#911eb4')  # Change this to your desired color\n",
        "\n",
        "# Change the color of the numbers next to the bars\n",
        "for text in ax.texts:\n",
        "    text.set_color('black')\n",
        "\n",
        "#plt.title('B', x=-1, y=1, fontsize=50, pad=20)\n",
        "plt.xlabel(\"Mean |SHAP Value|\", fontsize=14, fontweight='heavy', labelpad=8)\n",
        "plt.tick_params(axis=\"y\", direction=\"out\", labelsize=14)\n",
        "plt.tick_params(axis=\"x\", direction=\"out\", labelsize=14)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/shap_tabpfn_test.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C09esVZrIQPm"
      },
      "outputs": [],
      "source": [
        "#Calculate SHAP values for XGBoost.\n",
        "\n",
        "xgb_explainer = shap.Explainer(calibrated_xgb_model.predict, x_test_xgb)\n",
        "xgb_shap_values = xgb_explainer(x_test_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6O74ff97qW2H"
      },
      "outputs": [],
      "source": [
        "# Plot SHAP bar plot for XGBoost\n",
        "\n",
        "shap.plots.bar(xgb_shap_values, max_display=20, show=False)\n",
        "\n",
        "fig = plt.gcf()\n",
        "ax = plt.gca()\n",
        "fig.set_figheight(15)\n",
        "fig.set_figwidth(5)\n",
        "\n",
        "# Change the color of the bars\n",
        "for bar in ax.patches:\n",
        "    bar.set_color('#1f77b4')  # Change this to your desired color\n",
        "\n",
        "# Change the color of the numbers next to the bars\n",
        "for text in ax.texts:\n",
        "    text.set_color('black')\n",
        "\n",
        "#plt.title('B', x=-1, y=1, fontsize=50, pad=20)\n",
        "plt.xlabel(\"Mean |SHAP Value|\", fontsize=14, fontweight='heavy', labelpad=8)\n",
        "plt.tick_params(axis=\"y\", direction=\"out\", labelsize=14)\n",
        "plt.tick_params(axis=\"x\", direction=\"out\", labelsize=14)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/shap_xgb_test.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iXwkDFCZLkwp"
      },
      "outputs": [],
      "source": [
        "#Calculate SHAP values for LightGBM.\n",
        "\n",
        "lgb_explainer = shap.Explainer(calibrated_lgb_model.predict, x_test_lgb)\n",
        "lgb_shap_values = lgb_explainer(x_test_lgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o5kuLN88Tx26"
      },
      "outputs": [],
      "source": [
        "# Plot SHAP bar plot for LightGBM.\n",
        "\n",
        "shap.plots.bar(lgb_shap_values, max_display=20, show=False)\n",
        "\n",
        "fig = plt.gcf()\n",
        "ax = plt.gca()\n",
        "fig.set_figheight(15)\n",
        "fig.set_figwidth(5)\n",
        "\n",
        "# Change the color of the bars\n",
        "for bar in ax.patches:\n",
        "    bar.set_color('#3cb44b')  # Change this to your desired color\n",
        "\n",
        "# Change the color of the numbers next to the bars\n",
        "for text in ax.texts:\n",
        "    text.set_color('black')\n",
        "\n",
        "#plt.title('B', x=-1, y=1, fontsize=50, pad=20)\n",
        "plt.xlabel(\"Mean |SHAP Value|\", fontsize=14, fontweight='heavy', labelpad=8)\n",
        "plt.tick_params(axis=\"y\", direction=\"out\", labelsize=14)\n",
        "plt.tick_params(axis=\"x\", direction=\"out\", labelsize=14)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/shap_lgb_test.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XejwAq7pT_Gh"
      },
      "outputs": [],
      "source": [
        "#Calculate SHAP values for CatBoost.\n",
        "\n",
        "cb_explainer = shap.Explainer(calibrated_cb_model.predict, x_test_cb)\n",
        "cb_shap_values = cb_explainer(x_test_cb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NwBNWHF0b-P6"
      },
      "outputs": [],
      "source": [
        "# Plot SHAP bar plot for CatBoost.\n",
        "\n",
        "shap.plots.bar(cb_shap_values, max_display=20, show=False)\n",
        "\n",
        "fig = plt.gcf()\n",
        "ax = plt.gca()\n",
        "fig.set_figheight(15)\n",
        "fig.set_figwidth(5)\n",
        "\n",
        "# Change the color of the bars\n",
        "for bar in ax.patches:\n",
        "    bar.set_color('#ffe119')  # Change this to your desired color\n",
        "\n",
        "# Change the color of the numbers next to the bars\n",
        "for text in ax.texts:\n",
        "    text.set_color('black')\n",
        "\n",
        "#plt.title('B', x=-1, y=1, fontsize=50, pad=20)\n",
        "plt.xlabel(\"Mean |SHAP Value|\", fontsize=14, fontweight='heavy', labelpad=8)\n",
        "plt.tick_params(axis=\"y\", direction=\"out\", labelsize=14)\n",
        "plt.tick_params(axis=\"x\", direction=\"out\", labelsize=14)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/shap_cb_test.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SK13rLwHb13P"
      },
      "outputs": [],
      "source": [
        "#Calculate SHAP values for Random Forest.\n",
        "\n",
        "rf_explainer = shap.Explainer(calibrated_rf_model.predict, x_test_rf)\n",
        "rf_shap_values = rf_explainer(x_test_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wE_v_KfMb7CB"
      },
      "outputs": [],
      "source": [
        "# Plot SHAP bar plot for Random Forest.\n",
        "\n",
        "shap.plots.bar(rf_shap_values, max_display=20, show=False)\n",
        "\n",
        "fig = plt.gcf()\n",
        "ax = plt.gca()\n",
        "fig.set_figheight(15)\n",
        "fig.set_figwidth(5)\n",
        "\n",
        "# Change the color of the bars\n",
        "for bar in ax.patches:\n",
        "    bar.set_color('#e6194B')  # Change this to your desired color\n",
        "\n",
        "# Change the color of the numbers next to the bars\n",
        "for text in ax.texts:\n",
        "    text.set_color('black')\n",
        "\n",
        "#plt.title('B', x=-1, y=1, fontsize=50, pad=20)\n",
        "plt.xlabel(\"Mean |SHAP Value|\", fontsize=14, fontweight='heavy', labelpad=8)\n",
        "plt.tick_params(axis=\"y\", direction=\"out\", labelsize=14)\n",
        "plt.tick_params(axis=\"x\", direction=\"out\", labelsize=14)\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/Meningioma-Radiomics-Grading/shap_rf_test.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}